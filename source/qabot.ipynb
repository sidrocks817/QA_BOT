{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEN9vUc8BND4"
      },
      "outputs": [],
      "source": [
        "!pip install \\\n",
        "    \"pinecone-client[grpc]\" \\\n",
        "    \"langchain-pinecone\" \\\n",
        "    \"langchain-openai\" \\\n",
        "    \"langchain-text-splitters\" \\\n",
        "    \"langchain\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PINECONE_API_KEY = #enter your pinecone api key\n",
        "%env OPENAI_API_KEY = #enter your open ai api key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1WnYaT2QIhB",
        "outputId": "592733ac-c992-4818-af04-22e3148084e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PINECONE_API_KEY=26ed21f8-e8a2-42db-8ef0-cbc0a437a81f\n",
            "env: OPENAI_API_KEY=sk-proj-K71bz4rJYXMq9Ipj6RiUT3BlbkFJ6B1Ny92ZukbfNPxRQChw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "sPwvoncJLBwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "import os\n",
        "\n",
        "pc = Pinecone(api_key= os.environ['PINECONE_API_KEY'])\n",
        "\n",
        "index_name = \"docs-rag-chatbot\"\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=\"docs-rag-chatbot\",\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n"
      ],
      "metadata": {
        "id": "LNfGzpQFCy42"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "answers = []\n",
        "with open('/content/Ecommerce_FAQ_Chatbot_dataset.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "  for item in data[\"questions\"]:\n",
        "    answers.append(item['answer'])\n",
        "\n"
      ],
      "metadata": {
        "id": "aS3_oiWuDqNV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"Snowflake/snowflake-arctic-embed-s\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
      ],
      "metadata": {
        "id": "PBU-LT8NKuZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpiArVYvNhKq",
        "outputId": "68ed086c-a3c0-4c32-bffa-faf76054414d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "\n",
        "vector_store = PineconeVectorStore.from_texts(\n",
        "   texts = answers,\n",
        "   embedding = embeddings,\n",
        "   index_name = \"docs-rag-chatbot\",\n",
        "   namespace = \"ecommerce\"\n",
        ")"
      ],
      "metadata": {
        "id": "RZ-12nUoOFLp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#object to retrieve information\n",
        "query = \"Can I get a product demo before purchase?\"\n",
        "vector_store.similarity_search(query = query, k = 5, namespace = \"ecommerce\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwhUsWqWQk0L",
        "outputId": "f1bf99ff-603a-4438-9fd5-996314a04b95"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='We do not currently offer product demonstrations before purchase. However, you can find detailed product descriptions, specifications, and customer reviews on our website.'),\n",
              " Document(page_content=\"Products listed as 'coming soon' are not available for immediate purchase. Please sign up for notifications to be informed when the product becomes available.\"),\n",
              " Document(page_content=\"If a product is listed as 'coming soon' but not available for pre-order, you will need to wait until it is officially released and becomes available for purchase.\"),\n",
              " Document(page_content=\"If a product is listed as 'coming soon' but not available for pre-order, you will need to wait until it is officially released and becomes available for purchase.\"),\n",
              " Document(page_content='If a product is not listed on our website, it may not be available for purchase. We recommend exploring the available products or contacting our customer support team for further assistance.')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chains import RetrievalQA\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# import os\n",
        "\n",
        "# qa_chain = RetrievalQA.from_chain_type(\n",
        "#     llm = ChatOpenAI(temperature = 0.2, openai_api_key = os.environ[\"OPENAI_API_KEY\"]),\n",
        "#     chain_type = \"stuff\",\n",
        "#     retriever = vector_store.as_retriever(search_kwargs = {\"k\": 5})\n",
        "# )\n",
        "# query = \"my product\"\n",
        "# print(qa_chain.invoke({\"query\": query}).get(\"result\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wE87DQbSvRu",
        "outputId": "1893080e-e086-4a7c-d31c-fbf4f01bc8ed"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry to hear that your product is damaged. Please contact our customer support team immediately for assistance with the necessary steps for repair or replacement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chains import ConversationalRetrievalChain\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "retriever  = vector_store.as_retriever(search_kwargs = {\"k\": 5})\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key = 'answer')\n",
        "\n",
        "\n",
        "# Create the multipurpose chain\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "m_sajRNSUwWV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain(\"My product is damaged\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID_iVX57acqL",
        "outputId": "fe0f2294-55f8-4029-b124-82a1a8e97cfc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'My product is damaged',\n",
              " 'chat_history': [HumanMessage(content='My product is damaged'),\n",
              "  AIMessage(content=\"I'm sorry to hear that your product is damaged. Please contact our customer support team immediately for assistance with the necessary steps for repair or replacement.\")],\n",
              " 'answer': \"I'm sorry to hear that your product is damaged. Please contact our customer support team immediately for assistance with the necessary steps for repair or replacement.\",\n",
              " 'source_documents': [Document(page_content='If you receive a damaged product, please contact our customer support team immediately. We will assist you with the necessary steps for repair or replacement.'),\n",
              "  Document(page_content='If your product was damaged during shipping, please contact our customer support team immediately. We will guide you through the return and replacement process.'),\n",
              "  Document(page_content='If your product was damaged due to mishandling during shipping, please contact our customer support team immediately. We will assist you with the necessary steps for return and replacement.'),\n",
              "  Document(page_content='Our return policy generally covers products that are defective or damaged upon arrival. Damage due to improper use may not be eligible for a return. Please contact our customer support team for assistance.'),\n",
              "  Document(page_content='If a product is not available in your size, it may be temporarily out of stock. Please check back later or sign up for size notifications.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}